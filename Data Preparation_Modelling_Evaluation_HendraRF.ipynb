{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "503cad60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acer\\AppData\\Local\\Temp\\ipykernel_26232\\493728247.py:5: DtypeWarning: Columns (20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah baris: 466285 baris\n",
      "Jumlah kolom: 75 kolom\n"
     ]
    }
   ],
   "source": [
    "#Hendra Rizki Fatoni\n",
    "#Final Task_ID/X Partners_Data Scientist\n",
    "#Data Preparation_Modelling_Evaluation\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Memuat dataset\n",
    "file_path = 'loan_data_2007_2014.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Mendapatkan jumlah baris dan kolom\n",
    "num_rows, num_columns = data.shape\n",
    "print(f'Jumlah baris: {num_rows}', 'baris')\n",
    "print(f'Jumlah kolom: {num_columns}', 'kolom')\n",
    "\n",
    "# Mendefinisikan dictionary untuk mengganti nama kolom\n",
    "nama_kolom_baru = {\n",
    "    \"loan_status\": \"Status_Pinjaman\",\n",
    "}\n",
    "\n",
    "# Mengganti nama kolom\n",
    "data.rename(columns=nama_kolom_baru, inplace=True)\n",
    "# Mendapatkan nama kolom\n",
    "columns = data.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0fd98e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acer\\AppData\\Local\\Temp\\ipykernel_26232\\958471311.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[col].fillna(data[col].mean(), inplace=True)\n",
      "C:\\Users\\acer\\AppData\\Local\\Temp\\ipykernel_26232\\958471311.py:14: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[col].fillna(data[col].mode()[0], inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sukses menghapus kolom yang tidak ada nilainya\n"
     ]
    }
   ],
   "source": [
    "# Menghapus kolom yang seluruhnya kosong\n",
    "data_cleaned = data.dropna(axis=1, how='all')\n",
    "data=data_cleaned\n",
    "# Identifikasi kolom dengan nilai yang hilang\n",
    "missing_values = data.isnull().sum()\n",
    "\n",
    "# Tangani nilai yang hilang\n",
    "# Imputasi nilai yang hilang dengan mean untuk fitur numerik\n",
    "for col in data.select_dtypes(include=['int64', 'float64']).columns:\n",
    "    data[col].fillna(data[col].mean(), inplace=True)\n",
    "\n",
    "# Imputasi nilai yang hilang dengan modus untuk fitur kategorikal\n",
    "for col in data.select_dtypes(include=['object']).columns:\n",
    "    data[col].fillna(data[col].mode()[0], inplace=True)\n",
    "print(\"sukses menghapus kolom yang tidak ada nilainya\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9c6d43b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah baris: 466285 baris\n",
      "Jumlah kolom: 58 kolom\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Mendapatkan jumlah baris dan kolom\n",
    "num_rows, num_columns = data.shape\n",
    "print(f'Jumlah baris: {num_rows}', 'baris')\n",
    "print(f'Jumlah kolom: {num_columns}', 'kolom')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a88d2f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sukses mengganti outlier\n"
     ]
    }
   ],
   "source": [
    "def detect_outliers_iqr(df, columns):\n",
    "    outliers = {}\n",
    "    for col in columns:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        outliers[col] = df[(df[col] < lower_bound) | (df[col] > upper_bound)]\n",
    "    return outliers\n",
    "\n",
    "# Kolom numerik yang akan diperiksa untuk outlier\n",
    "# Mendefinisikan kolom numerik\n",
    "numerik_columns = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# Mengidentifikasi outlier\n",
    "outliers = detect_outliers_iqr(data, numerik_columns)\n",
    "outliers\n",
    "\n",
    "\n",
    "def remove_outliers_iqr(df, columns):\n",
    "    for col in columns:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "\n",
    "    return df\n",
    "# Menghapus outlier\n",
    "data_cleaned = remove_outliers_iqr(data, numerik_columns)\n",
    "\n",
    "def replace_outliers_iqr(df, columns):\n",
    "    for col in columns:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        df.loc[df[col] < lower_bound, col] = lower_bound\n",
    "        df.loc[df[col] > upper_bound, col] = upper_bound\n",
    "    return df\n",
    "\n",
    "# Mengganti outlier\n",
    "data_transformed = replace_outliers_iqr(data_cleaned, numerik_columns)\n",
    "data=data_transformed\n",
    "print(\"Sukses mengganti outlier\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8b303496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inisialisasi model LogisticRegression\n",
      "Inisialisasi model DecisionTreeClassifier\n",
      "Inisialisasi model RandomForestClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sukses Melatih model logreg\n",
      "sukses Melatih model dtree\n",
      "sukses Melatih model Random forest\n",
      "Logistic Regression:\n",
      "Training Accuracy: 0.9624130092111048\n",
      "Testing Accuracy: 0.9619331524711282\n",
      "AUC-ROC: 0.9306602822011852\n",
      "F1 Score: 0.9478445902877134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      8469\n",
      "           1       0.95      1.00      0.97     44894\n",
      "           2       0.33      0.02      0.03       173\n",
      "           3       0.57      0.20      0.29       148\n",
      "           4       0.54      0.18      0.27       377\n",
      "           5       0.98      1.00      0.99     36906\n",
      "           6       0.00      0.00      0.00       653\n",
      "           7       0.00      0.00      0.00       237\n",
      "           8       0.00      0.00      0.00      1400\n",
      "\n",
      "    accuracy                           0.96     93257\n",
      "   macro avg       0.48      0.37      0.39     93257\n",
      "weighted avg       0.94      0.96      0.95     93257\n",
      "\n",
      "===============================================\n",
      "\n",
      "Decision Tree:\n",
      "Training Accuracy: 1.0\n",
      "Testing Accuracy: 0.9597349260645314\n",
      "AUC-ROC: 0.7936873202379705\n",
      "F1 Score: 0.9600858738612024\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      8469\n",
      "           1       0.96      0.96      0.96     44894\n",
      "           2       0.15      0.12      0.13       173\n",
      "           3       0.90      0.92      0.91       148\n",
      "           4       0.97      0.93      0.95       377\n",
      "           5       1.00      1.00      1.00     36906\n",
      "           6       0.04      0.05      0.04       653\n",
      "           7       0.01      0.02      0.02       237\n",
      "           8       0.39      0.37      0.38      1400\n",
      "\n",
      "    accuracy                           0.96     93257\n",
      "   macro avg       0.60      0.59      0.60     93257\n",
      "weighted avg       0.96      0.96      0.96     93257\n",
      "\n",
      "\n",
      "Random Forest:\n",
      "Training Accuracy: 0.999989276944358\n",
      "Testing Accuracy: 0.9739429747900962\n",
      "AUC-ROC: 0.9332713278889053\n",
      "F1 Score: 0.9641790397199773\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99      8469\n",
      "           1       0.95      1.00      0.98     44894\n",
      "           2       1.00      0.01      0.02       173\n",
      "           3       0.99      0.82      0.90       148\n",
      "           4       0.98      0.95      0.96       377\n",
      "           5       1.00      1.00      1.00     36906\n",
      "           6       0.00      0.00      0.00       653\n",
      "           7       0.00      0.00      0.00       237\n",
      "           8       0.78      0.16      0.27      1400\n",
      "\n",
      "    accuracy                           0.97     93257\n",
      "   macro avg       0.74      0.55      0.57     93257\n",
      "weighted avg       0.96      0.97      0.96     93257\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "# Pisahkan fitur dan target\n",
    "# Mendefinisikan kolom numerik\n",
    "numerical_columns = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "X = data[numerical_columns]  # Ganti 'loan_status' dengan nama kolom target Anda\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Langkah 3: Menggunakan Label Encoding untuk kolom target 'loan_status'\n",
    "label_encoder = LabelEncoder()\n",
    "data['Status_Pinjaman'] = label_encoder.fit_transform(data['Status_Pinjaman'])\n",
    "y = data['Status_Pinjaman']  # nama kolom target\n",
    "\n",
    "# Inisialisasi StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Melakukan scaling pada fitur-fitur dalam X\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Bagi data yang telah di-scale menjadi set pelatihan dan pengujian\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#solver='lbfgs', max_iter=10000, verbose=1\n",
    "# Inisialisasi model\n",
    "logreg = LogisticRegression()\n",
    "print('Inisialisasi model LogisticRegression')\n",
    "dtree = DecisionTreeClassifier()\n",
    "print('Inisialisasi model DecisionTreeClassifier')\n",
    "rf = RandomForestClassifier()\n",
    "print('Inisialisasi model RandomForestClassifier')\n",
    "\n",
    "# Melatih model\n",
    "logreg.fit(X_train, y_train)\n",
    "print('sukses Melatih model logreg')\n",
    "dtree.fit(X_train, y_train)\n",
    "print('sukses Melatih model dtree')\n",
    "rf.fit(X_train, y_train)\n",
    "print('sukses Melatih model Random forest')\n",
    "\n",
    "# Prediksi dengan set pelatihan\n",
    "y_train_pred_logreg = logreg.predict(X_train)\n",
    "y_train_pred_dtree = dtree.predict(X_train)\n",
    "y_train_pred_rf = rf.predict(X_train)\n",
    "\n",
    "# Prediksi dengan set pengujian\n",
    "y_pred_logreg = logreg.predict(X_test)\n",
    "y_pred_dtree = dtree.predict(X_test)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "\n",
    "# Evaluasi model\n",
    "print(\"Logistic Regression:\")\n",
    "print(\"Training Accuracy:\", accuracy_score(y_train, y_train_pred_logreg))\n",
    "print(\"Testing Accuracy:\", accuracy_score(y_test, y_pred_logreg))\n",
    "print(\"AUC-ROC:\", roc_auc_score(y_test, logreg.predict_proba(X_test), multi_class='ovr'))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_logreg, average='weighted'))\n",
    "print(classification_report(y_test, y_pred_logreg))\n",
    "print(\"===============================================\")\n",
    "\n",
    "print(\"\\nDecision Tree:\")\n",
    "print(\"Training Accuracy:\", accuracy_score(y_train, y_train_pred_dtree))\n",
    "print(\"Testing Accuracy:\", accuracy_score(y_test,  y_pred_dtree))\n",
    "print(\"AUC-ROC:\", roc_auc_score(y_test, dtree.predict_proba(X_test), multi_class='ovr'))\n",
    "print(\"F1 Score:\", f1_score(y_test,  y_pred_dtree, average='weighted'))\n",
    "print(classification_report(y_test,  y_pred_dtree))\n",
    "\n",
    "print(\"\\nRandom Forest:\")\n",
    "print(\"Training Accuracy:\", accuracy_score(y_train, y_train_pred_rf))\n",
    "print(\"Testing Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(\"AUC-ROC:\", roc_auc_score(y_test, rf.predict_proba(X_test), multi_class='ovr'))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_rf, average='weighted'))\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
